- type: Future Talks
  members:
    - speaker: Chao Gao (University of Chicago)
      date: October 17, 2022 
      title: Iterative Algorithm for Discrete Structure Recovery
      abstract: We propose a general modeling and algorithmic framework for discrete structure recovery that can be applied to a wide range of problems. Under this framework, we are able to study the recovery of clustering labels, ranks of players, signs of regression coefficients, cyclic shifts, and even group elements from a unified perspective. A simple iterative algorithm is proposed for discrete structure recovery, which generalizes methods including Lloyd's algorithm and the power method. A linear convergence result for the proposed algorithm is established in this paper under appropriate abstract conditions on stochastic errors and initialization. We illustrate our general theory by applying it on several representative problems, (1) clustering in Gaussian mixture model, (2) approximate ranking, (3) sign recovery in compressed sensing, (4) multireference alignment, and (5) group synchronization, and show that minimax rate is achieved in each case.
      bio: Chao Gao is an Assistant Professor in Statistics at University of Chicago
      link: https://arxiv.org/pdf/1911.01018.pdf
    - speaker: Ye Zhang (University of Pennsylvania)
      date: October 24, 2022
      title: Sharp Theoretical Analysis of Spectral Methods in Clustering and Synchronization
      abstract: Spectral methods are simple but powerful approaches for extracting information from noisy data and have been widely used in various applications. In this talk, we demystify the success of spectral methods by establishing sharp theoretical guarantees for their performance in clustering and synchronization. (1) The first part of the talk is about a novel singular subspace perturbation analysis for spectral clustering. We consider two arbitrary matrices where one is a leave-one-column-out submatrix of the other one and establish a new perturbation upper bound for the distance between their corresponding singular subspaces. Powered by this tool, we obtain an explicit exponential error rate for the performance of spectral clustering in sub-Gaussian mixture models. (2) The second part of the talk is about the exact minimax optimality of a spectral method in the phase synchronization problem with additive Gaussian noises and incomplete data. We prove that it achieves the minimax lower bound of the problem with a matching leading constant under a squared l2 loss. This shows that the spectral method has the same performance as more sophisticated procedures including maximum likelihood estimation, generalized power method, and semidefinite programming, when consistent parameter estimation is possible.
      link: https://arxiv.org/abs/2205.14855 
      bio: Anderson Ye Zhang is an assistant professor in the Department of Statistics and Data Science at the University of Pennsylvania. Before joining Penn, he was a William H. Kruskal Instructor in Department of Statistics at the University of Chicago. He completed his Ph.D. in Statistics and Data Science at Yale University. His research includes spectral analysis, network analysis, clustering, ranking, and synchronization. 
    - speaker: Chao Zhang (University of Oxford)
      date: October 31, 2022
      title:  Volatility forecasting with machine learning and intraday commonality & Forecasting Realized Covariances via Graphs
      abstract: (Volatility forecasting) We apply machine learning models to forecast intraday realized volatility (RV), by exploiting commonality in intraday volatility via pooling stock data together, and by incorporating a proxy for the market volatility. Neural networks dominate linear regressions and tree models in terms of performance, due to their ability to uncover and model complex latent interactions among variables. Our findings remain robust when we apply trained models to new stocks that have not been included in the training set, thus providing new empirical evidence for a universal volatility mechanism among stocks. Finally, we propose a new approach to forecasting one-day-ahead RVs using past intraday RVs as predictors, and highlight interesting diurnal effects that aid the forecasting mechanism. The results demonstrate that the proposed methodology yields superior out-of-sample forecasts over a strong set of traditional baselines that only rely on past daily RVs.
      link: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4022147
    - speaker: Yuxin Chen  (University of Pennsylvania)
      date: November 7, 2022
      title: Inference and Uncertainty Quantification for Nonconvex Low-Rank Models
      abstract: Many high-dimensional problems involve reconstruction of a low-rank matrix from incomplete and corrupted observations. Despite substantial progress in designing efficient estimation algorithms, it remains largely unclear how to assess the uncertainty of the obtained low-rank estimates, and how to construct valid yet short confidence intervals for the unknown low-rank matrix.  In this talk, I will discuss how to perform inference and uncertainty quantification for two examples of low-rank models, (1) heteroskedastic PCA with missing data, and (2) noisy matrix completion. For both problems,  we identify statistically efficient estimators that admit non-asymptotic distributional characterizations, which in turn enable optimal construction of confidence intervals for, say, the unseen entries of the low-rank matrix of interest.  All this is accomplished by a powerful leave-one-out analysis framework that originated from probability and random matrix theory. This is based on joint work with Yuling Yan, Cong Ma, and Jianqing Fan. 
      link: https://arxiv.org/abs/2107.12365
      bio: Yuxin Chen is currently an associate professor in the Department of Statistics and Data Science at the University of Pennsylvania. Before joining UPenn, he was an assistant professor of electrical and computer engineering at Princeton University. He completed his Ph.D. in Electrical Engineering at Stanford University, and was also a postdoc scholar at Stanford Statistics. His current research interests include high-dimensional statistics, nonconvex optimization, and reinforcement learning. He has received the Alfred P. Sloan Research Fellowship, the ICCM best paper award (gold medal), the AFOSR and ARO Young Investigator Awards, the Google Research Scholar Award, and was selected as a finalist for the Best Paper Prize for Young Researchers in Continuous Optimization. He has also received the Princeton Graduate Mentoring Award. 
    - speaker: Melanie Schienle  (Karlsruhe Institute of Technology KIT)
      date: February 20, 2023
    - speaker: Agostino Capponi (Columbia University) 
      date: February 27, 2023
    - speaker: Petter Kolm (NYU) 
      date: February, 2023  
      

- type: Past Talks
  members:
    - speaker: Andreas Lehrmann
      date: June 13, 2022
      title: "Continuous-time Modelling of Irregular Time-Series"
      abstract: "Globally, capital markets have gone through a paradigm shift towards complete automation through artificial intelligence, turning it into a highly competitive area at the intersection of statistical models from various branches of machine learning. A principled understanding of the interactions between statistical models that operate in a common environment will soon be a key success factor for leaders in the field. In this talk I will first discuss the unique challenges of capital markets through the lens of machine learning and then provide an overview how Borealis AI addresses them from an atomistic and a holistic point of view. In the second part of the talk I will focus on our recent work on continuous-time modeling of irregular time-series and describe an expressive differential deformation of the Wiener process using neural ordinary differential equations. Finally, we will see how an augmentation of this model with a latent process driven by a stochastic differential equation can further increase the flexibility of this system and allows us to capture non-Markovian dynamics."
      bio: "Andreas Lehrmann is a machine learning researcher at Borealis AI. Previously, he held postdoctoral positions at Facebook Reality Labs and Disney Research. He received his Ph.D. at ETH Zurich and the Max-Planck-Institute for Intelligent Systems under a Microsoft Research scholarship."    
      link: https://proceedings.neurips.cc/paper/2021/file/2983e3047c0c730d3b7c022584717f3f-Paper.pdf
    - speaker: Chris Musco 
      date: June 6, 2022
      title: "Structured Covariance Estimation"
      abstract: "How many samples are needed to accurately learn the covariance matrix, C, of a distribution over d-dimensional vectors? In modern data applications where d is large, the answer is often unacceptably high: the sample complexity of covariance learning inherently depends poorly on dimension. In this talk I will discuss efforts to address this issue by designing data collection methods and learning algorithms which reduce complexity by leveraging a priori knowledge about the covariance matrix. Specifically, I will discuss the setting when C is known to have Toeplitz structure. Toeplitz covariance matrices arise in many applications, from time series analysis, to wireless communications, to medical imaging. In many of these applications, data collection is expensive, so reducing sample complexity is an important goal. We will start by taking a fresh look at classical and widely used algorithms, including methods based on selecting samples according to a sparse ruler. Then, I will introduce a novel sampling and estimation strategy that improves on existing methods in many settings. Our new approach for learning Toeplitz structured covariance utilizes tools from random matrix sketching, non-linear approximation theory, and sparse Fourier transform algorithms. It fits into a broader line of work which seeks to address problems in active learning using tools from theoretical computer science and randomized numerical linear algebra."
      bio: "Chris Musco is an Assistant Professor at New York University in the Tandon School of Engineering"
    - speaker: Lisa Goldberg 
      date: May 30, 2022 
      title:  James Stein for Eigenvectors
      abstract: "Estimated covariance matrices are widely used to construct portfolios with variance-minimizing optimization, yet the embedded sampling error produces portfolios with systematically underestimated variance. This effect is especially severe when the number of securities greatly exceeds the number of observations. In this high dimension low sample size (HL) regime, we show that a dispersion bias in the leading eigenvector of the estimated covariance matrix is a material source of distortion in the minimum variance portfolio. We correct the bias with the data-driven GPS (Global Positioning System) shrinkage estimator, which improves with the size of the market, and which is structurally identical to the James Stein estimator for a collection of averages. We illustrate the power of the GPS estimator with a numerical example, and conclude with open problems that have emerged from our research."
      bio: Lisa Goldberg is Professor of the Practice of Economics at University of California Berkeley. She is the co-director of the Berkeley Consortium for Data Analytics in Risk. She is Head of Research at Aperio Group, now part of BlackRock. 
      link: https://cdar.berkeley.edu/sites/default/files/publications/the_dispersion_bias_1.2022.pdf 
    - speaker: Vincent Tan
      date: May 23, 2022
      title: "Canonical Portfolios: Optimal Asset and Signal Combination"
      link: https://arxiv.org/abs/2202.10817 
    - speaker: Anish Agarwal  
      date: May 16, 2022
      title: "Causal Inference for Social and Engineering Systems"
      abstract: "What will happen to Y if we do A? A variety of meaningful social and engineering questions can be formulated this way: What will happen to a patient’s health if they are given a new therapy? What will happen to a country’s economy if policy-makers legislate a new tax? What will happen to a data center’s latency if a new congestion control protocol is used? We explore how to answer such counterfactual questions using observational data---which is increasingly available due to digitization and pervasive sensors---and/or very limited experimental data. The two key challenges are: (i) counterfactual prediction in the presence of latent confounders; (ii) estimation with modern datasets which are high-dimensional, noisy, and sparse. The key framework we introduce is connecting causal inference with tensor completion. In particular, we represent the various potential outcomes (i.e., counterfactuals) of interest through an order-3 tensor. The key theoretical results presented are: (i) Formal identification results establishing under what missingness patterns, latent confounding, and structure on the tensor is recovery of unobserved potential outcomes possible. (ii) Introducing novel estimators to recover these unobserved potential outcomes and proving they are finite-sample consistent and asymptotically normal. The efficacy of our framework is shown on high-impact applications. These include working with: (i) TaurRx Therapeutics to identify patient sub-populations where their therapy was effective. (ii) Uber Technologies on evaluating the impact of driver engagement policies without running an A/B test. (iii) The Poverty Action Lab at MIT to make personalized policy recommendations to improve childhood immunization rates across villages in Haryana, India. Finally, we discuss connections between causal inference, tensor completion, and offline reinforcement learning."
      bio: "Anish is currently a postdoctoral fellow at the Simons Institute at UC Berkeley. He did his PhD at MIT in EECS where he was advised by Alberto Abadie, Munther Dahleh, and Devavrat Shah. His research focuses on designing and analyzing methods for causal machine learning, and applying it to critical problems in social and engineering systems. He currently serves as a technical consultant to TauRx Therapeutics and Uber Technologies on questions related to experiment design and causal inference. Prior to the PhD, he was a management consultant at Boston Consulting Group. He received his BSc and MSc at Caltech."
      link: https://arxiv.org/abs/2109.15154
      recording: https://www.youtube.com/watch?v=MK5EXE7MkEk
    - speaker: Lorenzo Lucchese 
      date: May 9, 2022
      title: "Deep Limit Order Books"
    - speaker: Alvaro Arroyo
      date: May 2, 2022
      title: "Estimation Theory with Spectral Methods"
    - speaker: Qiong Wu
      date: April 11, 2022
      title: "Embedding Algorithms for Cross-Asset Equity Models"
    - speaker: Parley Ruogu Yang
      date: March 28, 2022
      title: "Adaptive Learning on Time Series: Methods and Financial Applications"
    - speaker: Christopher Policastro
      date: May 14, 2022
      title: "Singular Spectrum Analysis"
    - speaker:  Nicolas Cassia Terrazo, Qi Jin, Alexey Kapustin, Zhi Qi
      date: March 7, 2022
      title: "Co-jumping Behaviour in Time-Series and Financial Networks"
    - speaker: Adrien Hardy 
      date: February 28, 2022
      title: "Learning Factors Data Challenge"
    - speaker: Alik Sokolov
      date: February 21, 2022
      title: "ESG Case Studies"
    - speaker: Jianian Wang 
      date: February 14, 2022
      title: "A Review on Graph Neural Network Methods in Financial Applications"
    - speaker: Mihai Cucuringu
      date: February 7, 2022
      title: "Introduction to the Mechanics of Limit Order Books"
    - speaker: Milena Vuletic 
      date: January 24, 2022
      title: "Financial Time-Series Forecasting via GANs"
    - speaker:  Vincent Tan 
      date: January 17, 2022
      title: "Large covariance estimation, portfolio selection"
    - speaker:  Deborah Miori
      date: January 10, 2022
      title: " Fund2Vec: Mutual Funds Similarity using Graph Learning"
    - speaker: Yutong Lu 
      date: January 3, 2022
      title: "Network Effects in Financial High-Frequency Data"
    - speaker: Christopher Policastro
      date: December 20, 2022
      title: "Synopsis of MLECON Workshop"
    - speaker: Stefanos Bennett 
      date: December 13, 2022
      title: "Lead-lag detection and network clustering for multivariate time series with an application to the US equity market"
    - speaker: Nikolas Michael 
      date: December 6, 2022
      title: "Option Volume Imbalance as a predictor for spot market returns"
    - speaker: Felix Prenzel
      date: November 29, 2022
      title: "Analysis and Modelling of Client Order Flow in Limit Order Markets"
    - speaker:  Chao Zhang  
      date: November 22, 2022
      title: "Limit Order Books, Order Flow Imbalances, Price Impact, Lead-Lag Effects"
